{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [How To] Upload Label Predictions \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our latest <a href=\"https://www.datagym.ai/feature-introduction-upload-label-predictions/\">Blog post</a> we introduced the __\"Import Label\"__ feature which allows DataGym users to import their annotated image data directly into their DataGym Projects. Thereby, our users are now able to inspect and evaluate the results of their prediction models from within DataGym. This workshop aims to give a real-life example of how to use the __\"Import Labels\"__ feature with our <a href=\"https://docs.datagym.ai/documentation/python-api/getting-started\">Python API</a>. The code samples in this guide are also available as Jupyter Notebook at <a href=\"https://github.com/datagym-ai/datagym-python/tree/master/notebooks\">GitHub</a>.\n",
    "\n",
    "## Use Case\n",
    "\n",
    "In their cutting-edge, paper Wang et al. [1] presented a new chest X-ray database, namely __\"ChestX-ray8\"__, which comprises 108,948 frontal-view X-ray images of 32,717 unique patients with the text-mined eight disease image labels (where each image can have multi-labels), from the associated radiological reports using natural language processing. They demonstrated that commonly occurring __thoracic diseases__ can be spatially-located via their uniﬁed weakly-supervised multi-label image classiﬁcation and disease localization framework.\n",
    "\n",
    "<img src=\"https://media.datagym.ai/blog/chestxray/guide/thorax_scans.png\" width=\"500px\">\n",
    "\n",
    "Wang et al. made their findings and resources <a href=\"https://m.box.com/shared_item/https%3A%2F%2Fnihcc.app.box.com%2Fv%2FChestXray-NIHCC/browse/36938765345\">publicly available</a> to other researchers. Their datasets contain frontal-view chest X-ray PNG images as well as coordinates for bounding boxes that identify the location of the detected thoracic diseases. In this workshop, we use their ímages and annotated label-data to create a project in DataGym that imports and combines these resources and allows users to inspect and re-evaluate the predicted labels.\n",
    "\n",
    "### Our Starting Point\n",
    "\n",
    "We start our workshop with the <a href=\"https://m.box.com/shared_item/https%3A%2F%2Fnihcc.app.box.com%2Fv%2FChestXray-NIHCC/browse/36938765345\">resources</a> provided by Wang et al.:\n",
    "\n",
    "+  A <a href=\"https://media.datagym.ai/blog/chestxray/BBox_List_2017.csv\">.csv file</a> that contains the bounding boxes, which identify the location of thorax diseases in X-ray images. Preview:\n",
    "\n",
    "<img src=\"https://media.datagym.ai/blog/chestxray/guide/csv.png\" width=\"750px\">\n",
    "\n",
    "+ A set of 880 X-ray images. Example:\n",
    "\n",
    "<img src=\"https://media.datagym.ai/blog/chestxray/images/00027937_004.png\" width=\"350px\">\n",
    "\n",
    "### Our Goal\n",
    "\n",
    "Our goal is to import the Images and the labeled data into a DataGym Project. This allows the labelers to view the predicted diseases and to correct the size and location of the labels if necessary. Instead of labeling images from scratch, labelers have now the reduced task of correcting pre-labeled images.\n",
    "\n",
    "<img src=\"https://media.datagym.ai/blog/chestxray/guide/labeled_segment.png\" width=\"750px\">\n",
    "\n",
    "\n",
    "\n",
    "### References\n",
    "\n",
    "[1] Wang, Xiaosong, et al. \"Chestx-ray8: Hospital-scale chest x-ray database and benchmarks on weakly-supervised classification and localization of common thorax diseases.\" *Proceedings of the IEEE conference on computer vision and pattern recognition.* 2017.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the Data\n",
    "\n",
    "We use Pandas' DataFrames to read and process the prepared data from the .csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 984\n",
      "Number of images: 880\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image Index</th>\n",
       "      <th>Finding Label</th>\n",
       "      <th>Bbox [x</th>\n",
       "      <th>y</th>\n",
       "      <th>w</th>\n",
       "      <th>h]</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00013118_008.png</td>\n",
       "      <td>Atelectasis</td>\n",
       "      <td>225.084746</td>\n",
       "      <td>547.019217</td>\n",
       "      <td>86.779661</td>\n",
       "      <td>79.186441</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00014716_007.png</td>\n",
       "      <td>Atelectasis</td>\n",
       "      <td>686.101695</td>\n",
       "      <td>131.543498</td>\n",
       "      <td>185.491525</td>\n",
       "      <td>313.491525</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00029817_009.png</td>\n",
       "      <td>Atelectasis</td>\n",
       "      <td>221.830508</td>\n",
       "      <td>317.053115</td>\n",
       "      <td>155.118644</td>\n",
       "      <td>216.949153</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00014687_001.png</td>\n",
       "      <td>Atelectasis</td>\n",
       "      <td>726.237288</td>\n",
       "      <td>494.951420</td>\n",
       "      <td>141.016949</td>\n",
       "      <td>55.322034</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017877_001.png</td>\n",
       "      <td>Atelectasis</td>\n",
       "      <td>660.067797</td>\n",
       "      <td>569.780787</td>\n",
       "      <td>200.677966</td>\n",
       "      <td>78.101695</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Image Index Finding Label     Bbox [x           y           w  \\\n",
       "0  00013118_008.png   Atelectasis  225.084746  547.019217   86.779661   \n",
       "1  00014716_007.png   Atelectasis  686.101695  131.543498  185.491525   \n",
       "2  00029817_009.png   Atelectasis  221.830508  317.053115  155.118644   \n",
       "3  00014687_001.png   Atelectasis  726.237288  494.951420  141.016949   \n",
       "4  00017877_001.png   Atelectasis  660.067797  569.780787  200.677966   \n",
       "\n",
       "           h]  Unnamed: 6  Unnamed: 7  Unnamed: 8  \n",
       "0   79.186441         NaN         NaN         NaN  \n",
       "1  313.491525         NaN         NaN         NaN  \n",
       "2  216.949153         NaN         NaN         NaN  \n",
       "3   55.322034         NaN         NaN         NaN  \n",
       "4   78.101695         NaN         NaN         NaN  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_online = \"https://media.datagym.ai/blog/chestxray/BBox_List_2017.csv\"\n",
    "\n",
    "df = pd.read_csv(csv_online)\n",
    "print(\"Number of rows: {}\".format(len(df)))\n",
    "print(\"Number of images: {}\\n\".format(len(df['Image Index'].unique())))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, this is a bit messy. Therefore, we start by removing the unnecessary columns and changing the column names into a more readable format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>label</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>w</th>\n",
       "      <th>h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00013118_008.png</td>\n",
       "      <td>Atelectasis</td>\n",
       "      <td>225.084746</td>\n",
       "      <td>547.019217</td>\n",
       "      <td>86.779661</td>\n",
       "      <td>79.186441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00014716_007.png</td>\n",
       "      <td>Atelectasis</td>\n",
       "      <td>686.101695</td>\n",
       "      <td>131.543498</td>\n",
       "      <td>185.491525</td>\n",
       "      <td>313.491525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00029817_009.png</td>\n",
       "      <td>Atelectasis</td>\n",
       "      <td>221.830508</td>\n",
       "      <td>317.053115</td>\n",
       "      <td>155.118644</td>\n",
       "      <td>216.949153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00014687_001.png</td>\n",
       "      <td>Atelectasis</td>\n",
       "      <td>726.237288</td>\n",
       "      <td>494.951420</td>\n",
       "      <td>141.016949</td>\n",
       "      <td>55.322034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017877_001.png</td>\n",
       "      <td>Atelectasis</td>\n",
       "      <td>660.067797</td>\n",
       "      <td>569.780787</td>\n",
       "      <td>200.677966</td>\n",
       "      <td>78.101695</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         image_name        label           x           y           w  \\\n",
       "0  00013118_008.png  Atelectasis  225.084746  547.019217   86.779661   \n",
       "1  00014716_007.png  Atelectasis  686.101695  131.543498  185.491525   \n",
       "2  00029817_009.png  Atelectasis  221.830508  317.053115  155.118644   \n",
       "3  00014687_001.png  Atelectasis  726.237288  494.951420  141.016949   \n",
       "4  00017877_001.png  Atelectasis  660.067797  569.780787  200.677966   \n",
       "\n",
       "            h  \n",
       "0   79.186441  \n",
       "1  313.491525  \n",
       "2  216.949153  \n",
       "3   55.322034  \n",
       "4   78.101695  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.iloc[:,:6]  # select columns with content\n",
    "df.columns = ['image_name', 'label', 'x', 'y', 'w', 'h']\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks much better!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the Resources in DataGym\n",
    "\n",
    "Before we can import our labeled data into DataGym, we need to create a Project and set a Label Configuration. If you have any trouble following these steps, please visit DataGym's <a href=\"https://docs.datagym.ai/documentation/\">documentation</a>.\n",
    "\n",
    "## Create a Project\n",
    "\n",
    "Creating a Project in DataGym is rather simple. <a href=\"https://app.datagym.ai/\">Sign in</a> to your account and create a Project named 'Research Project'\n",
    "\n",
    "<img src=\"https://media.datagym.ai/blog/chestxray/guide/create_project.png\" width=\"650px\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Label Configuration\n",
    "\n",
    "In order to import annotated data into your Project, you need to define a Label Configuration first. The label configuration defines which labels and classifications are available in a Project. You can define geometries for labeling, attach classifications to them or create global classifications for more general questions.\n",
    "<br>\n",
    "<br>\n",
    "In our case, we will create a geometry for each of label from our .csv file. These labels are:\n",
    "+ Atelectasis\n",
    "+ Cardiomegaly\n",
    "+ Effusion\n",
    "+ Infiltrate\n",
    "+ Mass\n",
    "+ Nodule\n",
    "+ Pneumonia\n",
    "+ Pneumothorax\n",
    "\n",
    "You can also print these labels to check if the list is complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Atelectasis' 'Cardiomegaly' 'Effusion' 'Infiltrate' 'Mass' 'Nodule'\n",
      " 'Pneumonia' 'Pneumothorax']\n"
     ]
    }
   ],
   "source": [
    "print(df['label'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow the steps below to create a Label configuration <br> \n",
    "\n",
    "__Step 1:__ Navigate to the __\"Label configuration\"__ tab within your \"Research Project\"\n",
    "\n",
    "\n",
    "<img src=\"https://media.datagym.ai/blog/chestxray/guide/create_config_01.png\" width=\"650px\">\n",
    "\n",
    "<br>\n",
    "\n",
    "__Step 2:__ Add a __Geometry__ to your Label configuration and choose a __rectangle__\n",
    "\n",
    "<div>\n",
    "    <div >\n",
    "         <img src=\"https://media.datagym.ai/blog/chestxray/guide/create_config_02.png\" width=\"350px\">\n",
    "    </div>\n",
    "    <div>\n",
    "         <img src=\"https://media.datagym.ai/blog/chestxray/guide/create_config_03.png\" width=\"350px\">\n",
    "    </div>\n",
    "</div>\n",
    "    \n",
    "<br>\n",
    "\n",
    "__Step 3:__ Enter the first __label name__ as key in your new __geometry__\n",
    "\n",
    "You can choose a color and shortcut to better distinguish between your annotations.\n",
    "\n",
    "<img src=\"https://media.datagym.ai/blog/chestxray/guide/create_config_04.png\" width=\"450px\">\n",
    "\n",
    "<br>\n",
    "\n",
    "__Step 4:__ Click on __\"save edits\"__ to see your label entry in the overview\n",
    "\n",
    "<img src=\"https://media.datagym.ai/blog/chestxray/guide/create_config_05.png\" width=\"500px\">\n",
    "\n",
    "<br>\n",
    "\n",
    "__Step 5:__ Add the remaining labels from the list.\n",
    "The result should look like this:\n",
    "\n",
    "<img src=\"https://media.datagym.ai/blog/chestxray/guide/create_config_06.png\" width=\"500px\">\n",
    "\n",
    "Don't forget to save your configuration!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Dataset\n",
    "\n",
    "In order to upload images to our Project, we need to create a Dataset that can hold the images from our annotated data. This time we can use the Python API to quickly generate a Dataset directly from a Jupyter Notebook. Therefore, we need the following Client methods:\n",
    "\n",
    "\n",
    "```python\n",
    "Client.get_project_by_name(project_name)\n",
    "\n",
    "Client.create_dataset(name, owner, short_description)\n",
    "```\n",
    "\n",
    "If this is your first time using the Python API, please visit our <a href=\"https://docs.datagym.ai/documentation/python-api/getting-started\">Getting Started Guide</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datagym import Client\n",
    "\n",
    "client = Client(\"9489b7a6-fa4f-423e-8596-8ce5b3a74cb0\")\n",
    "client._endpoint.BASE_PATH = \"http://localhost:8080/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Dataset {'id': 'ee6115ec-bfc4-4a9f-8ee4-5037b771c90e', 'name': 'xray_images', 'short_description': 'Chest X-ray', 'timestamp': '1586174249366', 'owner': '3360f10f-a5ab-48a6-966c-cdba2d63116a', 'images': <List[Image] with 0 elements>}>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fetch your new Project first\n",
    "project = client.get_project_by_name(project_name=\"Research Project\")\n",
    "\n",
    "# create a dataset for the x-ray scans\n",
    "client.create_dataset(name=\"xray_images\", \n",
    "                      owner=project.owner, \n",
    "                      short_description=\"Chest X-ray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We easily created a Dataset via Python. But there aren't any images in this Dataset yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Images to the Dataset\n",
    "\n",
    "### Prepare a list with image URLs\n",
    "\n",
    "To upload images, we need a list of URLs that reference all of the annotated images. You can find the images on our server (https://media.datagym.ai/blog/chestxray/images/). Since we already now the image names from our .csv file, we can easily combine the \"image_name\" column with our image server path. Thereby, we can generate a URL list that links all the images from our .csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of URLs: 880\n",
      "Example URL: https://media.datagym.ai/blog/chestxray/images/00027278_007.png\n"
     ]
    }
   ],
   "source": [
    "image_url_path = \"https://media.datagym.ai/blog/chestxray/images/\"\n",
    "\n",
    "image_urls = image_url_path + df['image_name']  # combine the Server path and image names\n",
    "\n",
    "image_url_set = set(image_urls)  # convert numpy array into python set\n",
    "\n",
    "print(\"Number of URLs: {}\".format(len(image_url_set)))\n",
    "print(\"Example URL: {}\".format(list(image_url_set)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload the list with the Python API \n",
    "\n",
    "Now we can upload the images to our Dataset. Therefore, we use the Client class of the Python API.\n",
    "\n",
    "```python\n",
    "Client.create_images_from_urls(dataset_id, image_url_set)\n",
    "```\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = client.get_dataset_by_name(\"xray_images\")  # fetch the dataset from DataGym\n",
    "\n",
    "upload_results = client.create_images_from_urls(dataset_id=dataset.id, \n",
    "                                                image_url_set=image_url_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'internal_image_ID': 'bf496881-cb06-443b-a1b3-ee306dcb2a3b',\n",
       " 'external_image_ID': '00020819_002.png',\n",
       " 'imageUrl': 'https://media.datagym.ai/blog/chestxray/images/00020819_002.png',\n",
       " 'imageUploadStatus': 'SUCCESS'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upload_results[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataGym returns a success message for each uploaded image. The response contains the internal_image_IDs which are later needed as a reference to upload our annotated Data into DataGym's Datasets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an internal image ID reference Dictionary\n",
    "\n",
    "In the next step, we create a Dictionary that maps the internal image ID to the image name from our .csv file. This is needed to identify the images in our DataGym Project when we upload our annotated image data.\n",
    "\n",
    "    image_ids_dict:\n",
    "        \n",
    "        Dict[image_name] = internal_image_id \n",
    "    \n",
    "There are two ways to generate this Dictionary:\n",
    "\n",
    "1. By using the response data from the image upload:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_ids_dict = dict()\n",
    "\n",
    "for image_response in upload_results:\n",
    "    if image_response[\"imageUploadStatus\"] == \"SUCCESS\":\n",
    "        image_ids_dict[image_response[\"external_image_ID\"]] = image_response[\"internal_image_ID\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. By using the Images from your Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch your Dataset\n",
    "dataset = client.get_dataset_by_name(dataset_name=\"xray_images\")\n",
    "\n",
    "image_ids_dict = dict()\n",
    "\n",
    "for image in dataset.images:\n",
    "    image_ids_dict[image.image_name] = image.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect the Dataset to the Project\n",
    "\n",
    "We already created a Dataset and filled it with our images. The only thing that's left is to connect this dataset to our Research Project. The Python API provides a simple method to add a Dataset:\n",
    "    \n",
    "```python\n",
    "Client.add_dataset(dataset_name, project_name)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetch the Research Project and the CT Scan Dataset\n",
    "dataset = client.get_dataset_by_name(dataset_name=\"xray_images\")\n",
    "project = client.get_project_by_name(project_name=\"Research Project\")\n",
    "\n",
    "client.add_dataset(dataset_id=dataset.id, project_id=project.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the upload of annotated image data\n",
    "\n",
    "We want to upload the annotated image data from our .csv file to our DataGym Project. DataGym uses a specific format for annotated data imports. Therefore, we have to convert our rows from the .csv file into this specific form.\n",
    "\n",
    "## Understand the schema\n",
    "\n",
    "Before we start, let's have a look at our .csv again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>label</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>w</th>\n",
       "      <th>h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00013118_008.png</td>\n",
       "      <td>Atelectasis</td>\n",
       "      <td>225.084746</td>\n",
       "      <td>547.019217</td>\n",
       "      <td>86.779661</td>\n",
       "      <td>79.186441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00014716_007.png</td>\n",
       "      <td>Atelectasis</td>\n",
       "      <td>686.101695</td>\n",
       "      <td>131.543498</td>\n",
       "      <td>185.491525</td>\n",
       "      <td>313.491525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00029817_009.png</td>\n",
       "      <td>Atelectasis</td>\n",
       "      <td>221.830508</td>\n",
       "      <td>317.053115</td>\n",
       "      <td>155.118644</td>\n",
       "      <td>216.949153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00014687_001.png</td>\n",
       "      <td>Atelectasis</td>\n",
       "      <td>726.237288</td>\n",
       "      <td>494.951420</td>\n",
       "      <td>141.016949</td>\n",
       "      <td>55.322034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017877_001.png</td>\n",
       "      <td>Atelectasis</td>\n",
       "      <td>660.067797</td>\n",
       "      <td>569.780787</td>\n",
       "      <td>200.677966</td>\n",
       "      <td>78.101695</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         image_name        label           x           y           w  \\\n",
       "0  00013118_008.png  Atelectasis  225.084746  547.019217   86.779661   \n",
       "1  00014716_007.png  Atelectasis  686.101695  131.543498  185.491525   \n",
       "2  00029817_009.png  Atelectasis  221.830508  317.053115  155.118644   \n",
       "3  00014687_001.png  Atelectasis  726.237288  494.951420  141.016949   \n",
       "4  00017877_001.png  Atelectasis  660.067797  569.780787  200.677966   \n",
       "\n",
       "            h  \n",
       "0   79.186441  \n",
       "1  313.491525  \n",
       "2  216.949153  \n",
       "3   55.322034  \n",
       "4   78.101695  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every row in this table represents an annotated segment in an image. DataGym can add these annotations to its Project images when a specific JSON format is used. As an example we take the first row of the table above and convert it to valid DataGym JSON:\n",
    "\n",
    "    {\n",
    "    \"internal_image_ID\" : \"ebfbc807-5c52-431c-8f23-28a70f66488c\",\n",
    "    \"global_classifications\" : {},\n",
    "    \"keepData\": false,\n",
    "    \"labels\" : {\n",
    "        \"atelectasis\" :  [  \n",
    "                   {\n",
    "                     \"geometry\" : [ { \"x\" : 225.084746, \n",
    "                                      \"y\" : 547.019217, \n",
    "                                      \"h\" : 86.779661, \n",
    "                                      \"w\" : 79.186441  } ],\n",
    "                     \"classifications\" : {  }\n",
    "                   }\n",
    "                 ]\n",
    "               }\n",
    "    }\n",
    "    \n",
    "|Property | Description| \n",
    "|:---|:---|\n",
    "|__internal_image_ID__ | The internal ID to identify the image. <br><br> In order to address the correct image we have to replace the image name from our .csv with the internal image ID of our Dataset. For this case, we already prepared the *image_ids_dict* to get these internal image IDs by their image name.| \n",
    "|__keepData__ | If keepData is equal to false, all already existing labels for the current Image will be deleted after the labels upload. If keepData is equal to true, all new labels will be added to the already existing labels for the current Image. <br>Default value for keepData is true |\n",
    "|__global\\_classifications__ | Itcan be left empty because we haven't defined any additional global classifications in our Label configuration. |\n",
    "| __labels__ | A label describes a geometry within an image. <br><br>As you can see, the annotated image segments end up in the __labels__ attribute. Remember that we defined a __Geometry__ in our DataGym Project for every label of our .csv file. One of these labels is 'atelectasis', which we created as a rectangle.\n",
    "| __geometry__ | The __geometry__ attribute contains the coordinates of the annotated segment.\n",
    "| __classification__ | The attribute named __classifications__ can be left empty because we haven't defined any additional classifications in our Label configuration.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the .csv into DataGym JSON\n",
    "\n",
    "Follow this step-by-step guide to create the DataGym JSON from the .csv file\n",
    "\n",
    "### 1. Create a Dictionary template for annotated data\n",
    "\n",
    "First, we need to create a Dictionary that can hold all labels for every image in our .csv. Therefore, we define a nested Dictionary based on the image name and label. Since there can be multiple instances of annotated data (aka geometries) for each label, we initialize a (yet) empty list per label. The code snippet below results in a template Dictionary called __labels_per_image__ which has the following form: \n",
    "\n",
    "\n",
    "    labels_per_image: Dict[image_name][label]\n",
    "    \n",
    "    \n",
    "    labels_per_image =\n",
    "    \n",
    "        {\n",
    "            'image_name': {\n",
    "                               'label_1': [],\n",
    "                               'label_2': [],\n",
    "                               ...\n",
    "\n",
    "                          }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_per_image = {}\n",
    "\n",
    "for index,row in df.iterrows():  # iterate over the DataFrame rows\n",
    "    image_name = row['image_name']\n",
    "    label = row['label'].lower() # label keys must be lower case\n",
    "    \n",
    "    if image_name not in labels_per_image:\n",
    "        labels_per_image[image_name] = dict()\n",
    "    \n",
    "    if label not in labels_per_image[image_name]:\n",
    "        labels_per_image[image_name][label] = list()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create and Add Label Entries\n",
    "\n",
    "We iterate a second time over the DataFrame to generate a Label Entry for every row in our .csv. A __label_entry__ has the following form:\n",
    "\n",
    "    label_entry = \n",
    "    \n",
    "        {\n",
    "         'geometry': [{'x': 343.438229166667,\n",
    "                       'y': 446.198524305556,\n",
    "                       'h': 53.4755555555556,\n",
    "                       'w': 120.60444444444401}],\n",
    "         'classifications': {}\n",
    "        }\n",
    "    \n",
    "Then we add the Label Entries to our template Dictionary __labels_per_image__:\n",
    "\n",
    "    labels_per_image =\n",
    "    \n",
    "        {\n",
    "            'image_name': {\n",
    "                               'label_1': [label_entry_1, label_entry_2],\n",
    "                               'label_2': [label_entry_3],\n",
    "                               ...\n",
    "\n",
    "                          }\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,row in df.iterrows():\n",
    "    rectangle = {\n",
    "        \"x\": row['x'],\n",
    "        \"y\": row['y'],\n",
    "        \"h\": row['h'],\n",
    "        \"w\": row['w'],\n",
    "    }\n",
    "    \n",
    "    label_entry = {\n",
    "        \"geometry\": [rectangle],\n",
    "        \"classifications\" : {  }\n",
    "    }\n",
    "    \n",
    "    \n",
    "    image_name = row['image_name']\n",
    "    label = row['label'].lower()\n",
    "    \n",
    "    labels_per_image[image_name][label].append(label_entry)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'geometry': [{'x': 343.438229166667,\n",
       "   'y': 446.198524305556,\n",
       "   'h': 53.4755555555556,\n",
       "   'w': 120.60444444444401}],\n",
       " 'classifications': {}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_entry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Generate and fill the final template\n",
    "\n",
    "The final step is to create a list of Dictionaries that hold the image data and label data we defined above. At this point, we can recreate the schema introduced at the beginning of this section. The __label\\_data__ Dictionary is created for each image in our DataFrame. It also uses the __image_ids_dict__ to set the internal image IDs. The already formatted labels of the image can be set via the __labels_per_image__ Dictionary.\n",
    "    \n",
    "    label_data =\n",
    "    \n",
    "        {\n",
    "         \"internal_image_ID\" : image_ids_dict[image_name],\n",
    "         \"global_classifications\" : {},\n",
    "         \"keepData\": false,\n",
    "         \"labels\" : { labels_per_image[image_name] }\n",
    "        }\n",
    "        \n",
    "The only thing left to do is to create a list with all the labeled data. This List is now in a valid DataGym JSON format and contains all annotated image segments from the .csv file.\n",
    "    \n",
    "    label_data_list =\n",
    "    \n",
    "        [\n",
    "            label_data_1,\n",
    "            label_data_2,\n",
    "           \n",
    "            ...\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_data_list = []\n",
    "\n",
    "for image_name in df['image_name'].unique():  # iterate over all image names\n",
    "    label_data = {}\n",
    "    \n",
    "    label_data['image_name'] = image_name\n",
    "    label_data['internal_image_ID'] = image_ids_dict[image_name]\n",
    "    label_data['global_classifications'] = {}\n",
    "    label_data[\"keepData\"] = False\n",
    "    label_data['labels'] = labels_per_image[image_name]\n",
    "    \n",
    "    label_data_list.append(label_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the last __label\\_data__ object to get an example of the final form after the conversion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'global_classifications': {},\n",
      " 'image_name': '00026920_000.png',\n",
      " 'internal_image_ID': '337f70f0-e03f-498e-be84-fc0dbdd1ae31',\n",
      " 'keepData': False,\n",
      " 'labels': {'atelectasis': [{'classifications': {},\n",
      "                             'geometry': [{'h': 53.4755555555556,\n",
      "                                           'w': 120.60444444444401,\n",
      "                                           'x': 343.438229166667,\n",
      "                                           'y': 446.198524305556}]}]}}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "pprint.pprint(label_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the Annotated Data into the DataGym Project\n",
    "\n",
    "Now we can finally import the annotated data from the .csv file to our DataGym Project. We only need to pass the __label\\_data\\_list__ to the Python API Client.\n",
    "\n",
    "```python\n",
    "Client.import_label_data(project_id, label_data)\n",
    "```\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch your Research Project first\n",
    "project = client.get_project_by_name(project_name=\"Research Project\")\n",
    "\n",
    "errors = client.import_label_data(project_id=project.id, label_data=label_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors # returns a list with possible errors (JSON Format, label keys/values, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect your Results\n",
    "\n",
    "Visit DataGym to inspect your labeled images.\n",
    "\n",
    "<img src=\"https://media.datagym.ai/blog/chestxray/guide/labeled_segment.png\" width=\"700px\">\n",
    "\n",
    "This is it! You imported your labeled data into your DataGym Project. Now you can evaluate the labeled data by adjusting misplaced labels or adding labels that were missing. There is no need anymore to start labeling images from scratch, labelers have now the reduced task of correcting pre-labeled images. Thereby, you can save time labeling and quickly improve your prediction models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
